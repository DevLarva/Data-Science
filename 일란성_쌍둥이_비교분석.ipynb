{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrqa0B8HQkfzUSX5+h4W+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdh3620/Data-Science/blob/main/%EC%9D%BC%EB%9E%80%EC%84%B1_%EC%8C%8D%EB%91%A5%EC%9D%B4_%EB%B9%84%EA%B5%90%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHn0OCs5YnET"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from time import perf_counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from IPython.display import Markdown, display\n",
        "from google.colab import drive\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_ = Path('/content/drive/MyDrive/jorgy.luy/dd') #이미지 데이터 경로\n",
        "filepaths = list(dir_.glob(r'**/*.jpg'))\n",
        "def proc_img(filepath):\n",
        "    \n",
        "   \t#\t이미지데이터의 경로와 label데이터로 데이터프레임 형성\n",
        "    \n",
        "\n",
        "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
        "              for i in range(len(filepath))]\n",
        "\n",
        "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # 경로와 라벨 concatenate\n",
        "    df = pd.concat([filepath, labels], axis=1)\n",
        "\n",
        "    # index 재설정\n",
        "    df = df.sample(frac=1,random_state=0).reset_index(drop = True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = proc_img(filepaths)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "mfFzZatmbzck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 수집량 및 라벨 리스트 출력\n",
        "print(f'Number of pictures: {df.shape[0]}\\n')\n",
        "print(f'Number of different labels: {len(df.Label.unique())}\\n')\n",
        "print(f'Labels: {df.Label.unique()}')"
      ],
      "metadata": {
        "id": "f3pYawddb7jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 일부 출력\n",
        "fig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(df.Filepath[i]))\n",
        "    ax.set_title(df.Label[i], fontsize = 12)\n",
        "plt.tight_layout(pad=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7jLGTcxZR0mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 카테고리 분포 확인\n",
        "vc = df['Label'].value_counts()\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(x = vc.index, y = vc, palette = \"rocket\")\n",
        "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vH3LuTWNR8oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련데이터와 테스트 데이터의 분리 작업\n",
        "train_df,test_df = train_test_split(df, test_size=0.1,random_state=0)\n",
        "train_df.shape,test_df.shape"
      ],
      "metadata": {
        "id": "9jspdefgSBRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 전처리\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory('/content/drive/MyDrive/jorgy.luy',\n",
        "                                                 target_size = (150, 150),\n",
        "                                                 batch_size = 160,\n",
        "                                                 class_mode = 'categorical',subset='training')\n",
        "val_gen  = train_datagen.flow_from_directory('/content/drive/MyDrive/jorgy.luy',\n",
        "                                                 target_size = (150, 150),\n",
        "                                                 batch_size = 160,\n",
        "                                                 class_mode = 'categorical',subset='validation')"
      ],
      "metadata": {
        "id": "aWBRDzytSBTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Adding convolutional layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "\n",
        "\n",
        "# Step 4 - Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "# Compiling the CNN\n",
        "cnn.compile(optimizer = 'adam', \n",
        "            loss = 'categorical_crossentropy', \n",
        "            metrics = ['accuracy'])\n",
        "cnn.summary()"
      ],
      "metadata": {
        "id": "1P4V4cP_c_x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 확인\n",
        "cnn.fit(x = train_gen, validation_data = val_gen, epochs = 20)"
      ],
      "metadata": {
        "id": "9huTccMzTDIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강으로 이미지 모델 성능 높이기\n",
        "def create_gen():\n",
        "    # 생성기 및 데이터 증강으로 이미지 로드\n",
        "    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        validation_split=0.1\n",
        "    )\n",
        "\n",
        "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "    train_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath', \n",
        "        y_col='Label', \n",
        "        target_size=(224, 224), \n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset='training',\n",
        "        rotation_range=30, # 회전제한 각도 30도\n",
        "        zoom_range=0.15, # 확대 축소 15%\n",
        "        width_shift_range=0.2, # 좌우이동 20%\n",
        "        height_shift_range=0.2, # 상하이동 20%\n",
        "        shear_range=0.15, # 반시계방햐의 각도\n",
        "        horizontal_flip=True, # 좌우 반전 True\n",
        "        fill_mode=\"nearest\"\n",
        "       \n",
        "    )\n",
        "\n",
        "    val_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset='validation',\n",
        "        rotation_range=30,\n",
        "        zoom_range=0.15,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    test_images = test_generator.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    return train_generator,test_generator,train_images,val_images,test_images\n",
        "    "
      ],
      "metadata": {
        "id": "qmYpavzsSBXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"DenseNet201\": {\"model\":tf.keras.applications.DenseNet201, \"perf\":0},\n",
        "    \"EfficientNetB0\": {\"model\":tf.keras.applications.EfficientNetB0, \"perf\":0},\n",
        "    \"EfficientNetB1\": {\"model\":tf.keras.applications.EfficientNetB1, \"perf\":0},\n",
        "    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"MobileNetV3Large\": {\"model\":tf.keras.applications.MobileNetV3Large, \"perf\":0},\n",
        "    \"ResNet152V2\": {\"model\":tf.keras.applications.ResNet152V2, \"perf\":0},\n",
        "    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n",
        "    \"ResNet50V2\": {\"model\":tf.keras.applications.ResNet50V2, \"perf\":0},\n",
        "    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0},\n",
        "    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n",
        "    \"Xception\": {\"model\":tf.keras.applications.Xception, \"perf\":0}\n",
        "}\n",
        "# Create the generators\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "print('\\n')\n",
        "\n",
        "def get_model(model):\n",
        "# Load the pretained model\n",
        "    kwargs =    {'input_shape':(224, 224, 3),\n",
        "                'include_top':False,\n",
        "                'weights':'imagenet',\n",
        "                'pooling':'avg'}\n",
        "    \n",
        "    pretrained_model = model(**kwargs)\n",
        "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
        "    \n",
        "    inputs = pretrained_model.input\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(6, activation='softmax')(x)\n",
        "    # 라벨 개수가 8개이기 때문에 Dencs도 8로 설정\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Train모델 학습\n",
        "for name, model in models.items():\n",
        "    \n",
        "    # 전이 학습 모델 가져오기\n",
        "    m = get_model(model['model'])\n",
        "    models[name]['model'] = m\n",
        "    \n",
        "    start = perf_counter()\n",
        "    \n",
        "    # 모델 학습\n",
        "    history = m.fit(train_images,validation_data=val_images,epochs=1,verbose=0)\n",
        "    \n",
        "    # 학습시간과 val_accuracy 저장\n",
        "    duration = perf_counter() - start\n",
        "    duration = round(duration,2)\n",
        "    models[name]['perf'] = duration\n",
        "    print(f\"{name:20} trained in {duration} sec\")\n",
        "    \n",
        "    val_acc = history.history['val_accuracy']\n",
        "    models[name]['val_acc'] = [round(v,4) for v in val_acc]"
      ],
      "metadata": {
        "id": "OR2wfQaySBZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    \n",
        "    # 테스트 이미지의 라벨을 예측 하는 코드 \n",
        "    pred = models[name]['model'].predict(test_images)\n",
        "    pred = np.argmax(pred,axis=1)\n",
        "\n",
        "    # 라벨을 매핑하는 코드\n",
        "    labels = (train_images.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "    pred = [labels[k] for k in pred]\n",
        "\n",
        "    y_test = list(test_df.Label)\n",
        "    acc = accuracy_score(y_test,pred)\n",
        "    models[name]['acc'] = round(acc,4)\n",
        "    print(f'**{name} has a {acc * 100:.2f}% accuracy on the test set**')\n",
        "   \n",
        "# 데이터 프레임의 결과를 생성\n",
        "models_result = []\n",
        "\n",
        "for name, v in models.items():\n",
        "    models_result.append([ name, models[name]['val_acc'][-1], \n",
        "                          models[name]['acc'],\n",
        "                          models[name]['perf']])\n",
        "    \n",
        "df_results = pd.DataFrame(models_result, \n",
        "                          columns = ['model','val_accuracy','accuracy','Training time (sec)'])\n",
        "df_results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
        "df_results.reset_index(inplace=True,drop=True)\n",
        "df_results"
      ],
      "metadata": {
        "id": "ZrGLhg23CUvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 모델에 대한 테스트 데이터를 이용한 정확도 시각화 \n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'accuracy', data = df_results)\n",
        "plt.title('Accuracy on the test set (after 1 epoch))', fontsize = 15)\n",
        "plt.ylim(0,1)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O1Tj-asSCXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 걸린 시간 시각화 \n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\n",
        "plt.title('Training time for each model in sec', fontsize = 15)\n",
        "# plt.ylim(0,20)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vx4kPAj8CY8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도가 높고 학습에 걸린 시간이 짧은 모델에 대한 성능 확인\n",
        "train_df,test_df = train_test_split(df, test_size=0.1, random_state=0)\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "\n",
        "model = get_model(tf.keras.applications.DenseNet201)\n",
        "history = model.fit(train_images,validation_data=val_images,epochs=10)"
      ],
      "metadata": {
        "id": "mKO3CcgpCdKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o481rOElCfQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GJri9t22CgpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "    \n",
        "y_test = list(test_df.Label)\n",
        "acc = accuracy_score(y_test,pred)\n",
        "print(f'Accuracy on the test set: {acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "1aFQc78wCilF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도가 높고 학습에 걸린 시간이 짧은 모델에 대한 성능 확인(2)\n",
        "train_df,test_df = train_test_split(df, test_size=0.1, random_state=0)\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "model = get_model(tf.keras.applications.ResNet50V2)\n",
        "history = model.fit(train_images,validation_data=val_images,epochs=10)"
      ],
      "metadata": {
        "id": "_WJS6YQLCin1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v8B7zSWgCipY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cljPZwzoCqJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))\n",
        "    \n",
        "y_test = list(test_df.Label)\n",
        "acc = accuracy_score(y_test,pred)\n",
        "printmd(f'# Accuracy on the test set: {acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "gI-Lcx1dCqL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_test, pred, zero_division=1)\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "JUBRaHFmCqOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix 시각화\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, pred, normalize='true')\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(cf_matrix, annot=False, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)),cbar=False)\n",
        "plt.title('Normalized Confusion Matrix', fontsize = 23)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8NyV1NosyLpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 예측\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from tf.keras.applications.densenet.densenet201 import DenseNet201\n",
        "from tensorflow.keras.applications.densenet201 import preprocess_input\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))\n",
        "class_dictionary = {'anna': 0,\n",
        "                    'black-w': 1,\n",
        "                    'ele': 2,\n",
        "                    'jorgy': 3,\n",
        "                    'lucy': 4,\n",
        "                    'lucy-w': 5,\n",
        "                    'luy': 6,\n",
        "                    'real': 7}\n",
        "IMAGE_SIZE    = (224, 224)\n",
        "\n",
        "test_image = image.load_img(test_df.iloc[number_1, 0]\n",
        "                            ,target_size =IMAGE_SIZE )\n",
        "test_image = image.img_to_array(test_image)\n",
        "plt.imshow(test_image/255.);\n",
        "\n",
        "test_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], test_image.shape[2]))\n",
        "test_image = preprocess_input(test_image)\n",
        "prediction = model.predict(test_image)\n",
        "\n",
        "df = pd.DataFrame({'pred':prediction[0]})\n",
        "df = df.sort_values(by='pred', ascending=False, na_position='first')\n",
        "printmd(f\"## 예측률 : {(df.iloc[0]['pred'])* 100:.2f}%\")\n",
        "\n",
        "for x in class_dictionary:\n",
        "  if class_dictionary[x] == (df[df == df.iloc[0]].index[0]):\n",
        "    printmd(f\"### Class prediction = {x}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "jC4hksZF0-GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨과 함께 테스트 데이터의 결과를 총 50개 출력\n",
        "fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(22, 15),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for  i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n",
        "    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\", fontsize = 15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m9yKCw9FC0Pb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}